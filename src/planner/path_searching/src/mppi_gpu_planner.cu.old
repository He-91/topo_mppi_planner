#include "path_searching/mppi_gpu_planner.h"
#include "path_searching/mppi_cuda_kernel.cuh"
#include <ros/ros.h>
#include <chrono>

namespace ego_planner {

MPPIGPUPlanner::MPPIGPUPlanner() 
    : initialized_(false),
      stream_(nullptr),
      own_stream_(false),
      d_initial_state_(nullptr),
      d_goal_pos_(nullptr),
      d_goal_vel_(nullptr),
      d_nominal_control_(nullptr),
      d_trajectory_costs_(nullptr),
      d_weights_(nullptr),
      d_min_cost_(nullptr),
      d_weight_sum_(nullptr),
      d_edt_array_(nullptr),
      edt_texture_(0),
      texture_initialized_(false),
      d_dynamic_positions_(nullptr),
      d_dynamic_radii_(nullptr),
      num_dynamic_obstacles_(0),
      dynamic_horizon_(0),
      dynamic_dt_(0.0f),
      d_control_samples_(nullptr),
      d_updated_control_(nullptr) {
}

MPPIGPUPlanner::~MPPIGPUPlanner() {
    if (initialized_) {
        freeGPUMemory();
        
        // üöÄ Destroy stream if we own it
        if (own_stream_ && stream_ != nullptr) {
            cudaStreamDestroy(stream_);
            stream_ = nullptr;
        }
    }
}

void MPPIGPUPlanner::initialize(const Params& params, cudaStream_t stream) {
    params_ = params;
    
    // üöÄ Setup CUDA Stream (inspired by MPPI-Generic)
    if (stream == nullptr) {
        // Create our own stream for async operations
        CUDA_CHECK(cudaStreamCreate(&stream_));
        own_stream_ = true;
        ROS_INFO("[MPPI-GPU] Created new CUDA stream for async operations");
    } else {
        // Use provided stream
        stream_ = stream;
        own_stream_ = false;
        ROS_INFO("[MPPI-GPU] Using provided CUDA stream");
    }
    
    // Allocate host memory (pinned for async transfer)
    h_trajectory_costs_.resize(params_.num_samples);
    h_weights_.resize(params_.num_samples);
    h_nominal_control_.resize(params_.horizon_steps * 3, 0.0f);
    
    // Allocate GPU memory
    allocateGPUMemory();
    
    initialized_ = true;
    ROS_INFO("[MPPI-GPU] ‚úÖ Initialized with %d samples, horizon=%d (stream=%p)", 
             params_.num_samples, params_.horizon_steps, (void*)stream_);
}

void MPPIGPUPlanner::allocateGPUMemory() {
    // State and goal
    CUDA_CHECK(cudaMalloc(&d_initial_state_, STATE_DIM * sizeof(float)));
    CUDA_CHECK(cudaMalloc(&d_goal_pos_, 3 * sizeof(float)));
    CUDA_CHECK(cudaMalloc(&d_goal_vel_, 3 * sizeof(float)));
    
    // Control sequence
    CUDA_CHECK(cudaMalloc(&d_nominal_control_, 
                         params_.horizon_steps * CONTROL_DIM * sizeof(float)));
    
    // Trajectory costs and weights
    CUDA_CHECK(cudaMalloc(&d_trajectory_costs_, params_.num_samples * sizeof(float)));
    CUDA_CHECK(cudaMalloc(&d_weights_, params_.num_samples * sizeof(float)));
    
    // Min cost and weight sum (single values)
    CUDA_CHECK(cudaMalloc(&d_min_cost_, sizeof(float)));
    CUDA_CHECK(cudaMalloc(&d_weight_sum_, sizeof(float)));
    
    // üî• Control samplesÂíåupdated control
    size_t control_samples_size = params_.num_samples * params_.horizon_steps * CONTROL_DIM * sizeof(float);
    CUDA_CHECK(cudaMalloc(&d_control_samples_, control_samples_size));
    CUDA_CHECK(cudaMalloc(&d_updated_control_, params_.horizon_steps * CONTROL_DIM * sizeof(float)));
    
    ROS_INFO("[MPPI-GPU] GPU memory allocated successfully");
}

void MPPIGPUPlanner::freeGPUMemory() {
    if (d_initial_state_) cudaFree(d_initial_state_);
    if (d_goal_pos_) cudaFree(d_goal_pos_);
    if (d_goal_vel_) cudaFree(d_goal_vel_);
    if (d_nominal_control_) cudaFree(d_nominal_control_);
    if (d_trajectory_costs_) cudaFree(d_trajectory_costs_);
    if (d_weights_) cudaFree(d_weights_);
    if (d_min_cost_) cudaFree(d_min_cost_);
    if (d_weight_sum_) cudaFree(d_weight_sum_);
    
    // üöÄ Free texture resources
    if (texture_initialized_ && edt_texture_ != 0) {
        cudaDestroyTextureObject(edt_texture_);
        edt_texture_ = 0;
    }
    if (d_edt_array_) {
        cudaFreeArray(d_edt_array_);
        d_edt_array_ = nullptr;
    }
    texture_initialized_ = false;
    
    // üî• Free dynamic obstacles data
    if (d_dynamic_positions_) cudaFree(d_dynamic_positions_);
    if (d_dynamic_radii_) cudaFree(d_dynamic_radii_);
    
    if (d_control_samples_) cudaFree(d_control_samples_);
    if (d_updated_control_) cudaFree(d_updated_control_);
}

void MPPIGPUPlanner::setEDTMap(const float* edt_data, 
                               int size_x, int size_y, int size_z,
                               float resolution, 
                               float origin_x, float origin_y, float origin_z) {
    grid_size_x_ = size_x;
    grid_size_y_ = size_y;
    grid_size_z_ = size_z;
    grid_resolution_ = resolution;
    grid_origin_x_ = origin_x;
    grid_origin_y_ = origin_y;
    grid_origin_z_ = origin_z;
    
    // üöÄ Free old texture if exists
    if (texture_initialized_ && edt_texture_ != 0) {
        cudaDestroyTextureObject(edt_texture_);
        edt_texture_ = 0;
    }
    if (d_edt_array_) {
        cudaFreeArray(d_edt_array_);
        d_edt_array_ = nullptr;
    }
    
    // üöÄ Create 3D CUDA array for texture
    cudaChannelFormatDesc channelDesc = cudaCreateChannelDesc<float>();
    cudaExtent volumeSize = make_cudaExtent(size_x, size_y, size_z);
    CUDA_CHECK(cudaMalloc3DArray(&d_edt_array_, &channelDesc, volumeSize));
    
    // üöÄ Copy EDT data to 3D array
    cudaMemcpy3DParms copyParams = {0};
    copyParams.srcPtr = make_cudaPitchedPtr((void*)edt_data, size_x * sizeof(float), 
                                            size_x, size_y);
    copyParams.dstArray = d_edt_array_;
    copyParams.extent = volumeSize;
    copyParams.kind = cudaMemcpyHostToDevice;
    CUDA_CHECK(cudaMemcpy3D(&copyParams));
    
    // üöÄ Create texture object with hardware-accelerated interpolation
    cudaResourceDesc resDesc;
    memset(&resDesc, 0, sizeof(resDesc));
    resDesc.resType = cudaResourceTypeArray;
    resDesc.res.array.array = d_edt_array_;
    
    cudaTextureDesc texDesc;
    memset(&texDesc, 0, sizeof(texDesc));
    texDesc.addressMode[0] = cudaAddressModeBorder;  // Clamp to edge
    texDesc.addressMode[1] = cudaAddressModeBorder;
    texDesc.addressMode[2] = cudaAddressModeBorder;
    texDesc.filterMode = cudaFilterModeLinear;  // Hardware linear interpolation
    texDesc.readMode = cudaReadModeElementType;
    texDesc.normalizedCoords = 0;  // Use absolute coordinates
    
    CUDA_CHECK(cudaCreateTextureObject(&edt_texture_, &resDesc, &texDesc, nullptr));
    texture_initialized_ = true;
    
    ROS_INFO("[MPPI-GPU] üöÄ EDT map uploaded as 3D texture: %dx%dx%d, res=%.2f", 
             size_x, size_y, size_z, resolution);
}

void MPPIGPUPlanner::setDynamicObstacles(const std::vector<Eigen::Vector3d>& positions,
                                        const std::vector<float>& radii,
                                        int num_obstacles,
                                        int horizon,
                                        float dt) {
    num_dynamic_obstacles_ = num_obstacles;
    dynamic_horizon_ = horizon;
    dynamic_dt_ = dt;
    
    if (num_obstacles == 0 || positions.empty()) {
        // Clear dynamic obstacles
        if (d_dynamic_positions_) {
            cudaFree(d_dynamic_positions_);
            d_dynamic_positions_ = nullptr;
        }
        if (d_dynamic_radii_) {
            cudaFree(d_dynamic_radii_);
            d_dynamic_radii_ = nullptr;
        }
        num_dynamic_obstacles_ = 0;
        return;
    }
    
    // üî• Prepare host data in flat format
    std::vector<float3> h_positions(num_obstacles * horizon);
    for (int i = 0; i < num_obstacles; ++i) {
        for (int t = 0; t < horizon; ++t) {
            int idx = i * horizon + t;
            if (idx < (int)positions.size()) {
                h_positions[i * horizon + t] = make_float3(
                    (float)positions[idx].x(),
                    (float)positions[idx].y(),
                    (float)positions[idx].z()
                );
            } else {
                // Use last available position if not enough predictions
                int last_idx = (int)positions.size() - 1;
                h_positions[i * horizon + t] = make_float3(
                    (float)positions[last_idx].x(),
                    (float)positions[last_idx].y(),
                    (float)positions[last_idx].z()
                );
            }
        }
    }
    
    // üî• Free old data
    if (d_dynamic_positions_) cudaFree(d_dynamic_positions_);
    if (d_dynamic_radii_) cudaFree(d_dynamic_radii_);
    
    // üî• Allocate and copy to GPU
    size_t pos_size = num_obstacles * horizon * sizeof(float3);
    size_t radii_size = num_obstacles * sizeof(float);
    
    CUDA_CHECK(cudaMalloc(&d_dynamic_positions_, pos_size));
    CUDA_CHECK(cudaMalloc(&d_dynamic_radii_, radii_size));
    
    CUDA_CHECK(cudaMemcpyAsync(d_dynamic_positions_, h_positions.data(), pos_size,
                              cudaMemcpyHostToDevice, stream_));
    CUDA_CHECK(cudaMemcpyAsync(d_dynamic_radii_, radii.data(), radii_size,
                              cudaMemcpyHostToDevice, stream_));
    
    CUDA_CHECK(cudaStreamSynchronize(stream_));
    
    ROS_INFO("[MPPI-GPU] üî• Dynamic obstacles updated: %d obstacles √ó %d timesteps (dt=%.2fs)",
             num_obstacles, horizon, dt);
}

bool MPPIGPUPlanner::plan(const Vector3d& start_pos,
                          const Vector3d& start_vel,
                          const Vector3d& goal_pos,
                          const Vector3d& goal_vel,
                          std::vector<Vector3d>& optimal_path) {
    if (!initialized_) {
        ROS_ERROR("[MPPI-GPU] Not initialized!");
        return false;
    }
    
    auto t_start = std::chrono::high_resolution_clock::now();
    
    // Prepare initial state
    float h_initial_state[STATE_DIM] = {
        (float)start_pos.x(), (float)start_pos.y(), (float)start_pos.z(),
        (float)start_vel.x(), (float)start_vel.y(), (float)start_vel.z()
    };
    
    h_goal_pos_[0] = (float)goal_pos.x();
    h_goal_pos_[1] = (float)goal_pos.y();
    h_goal_pos_[2] = (float)goal_pos.z();
    h_goal_vel_[0] = (float)goal_vel.x();
    h_goal_vel_[1] = (float)goal_vel.y();
    h_goal_vel_[2] = (float)goal_vel.z();
    
    // üöÄ Copy to GPU (Async transfers with stream)
    CUDA_CHECK(cudaMemcpyAsync(d_initial_state_, h_initial_state, 
                         STATE_DIM * sizeof(float), cudaMemcpyHostToDevice, stream_));
    CUDA_CHECK(cudaMemcpyAsync(d_goal_pos_, h_goal_pos_, 
                         3 * sizeof(float), cudaMemcpyHostToDevice, stream_));
    CUDA_CHECK(cudaMemcpyAsync(d_goal_vel_, h_goal_vel_, 
                         3 * sizeof(float), cudaMemcpyHostToDevice, stream_));
    CUDA_CHECK(cudaMemcpyAsync(d_nominal_control_, h_nominal_control_.data(),
                         params_.horizon_steps * CONTROL_DIM * sizeof(float), 
                         cudaMemcpyHostToDevice, stream_));
    
    // üî• Iterative MPPI Loop (on GPU)
    int num_iters = params_.use_iterative_mppi ? params_.num_iterations : 1;
    float total_rollout_ms = 0.0f;
    float total_weight_ms = 0.0f;
    float total_update_ms = 0.0f;
    
    for (int iter = 0; iter < num_iters; ++iter) {
        // üî• Temperature annealing: lambda_k = lambda_0 * (1 - k/K)^2
        float lambda_annealed = params_.lambda;
        if (num_iters > 1) {
            float ratio = (float)iter / (float)(num_iters - 1);
            lambda_annealed = params_.lambda * (1.0f - ratio) * (1.0f - ratio);
            lambda_annealed = fmaxf(lambda_annealed, 0.01f);  // Min temperature
        }
        
        // Launch rollout kernel (on stream)
        auto t_rollout_start = std::chrono::high_resolution_clock::now();
        launchRolloutKernel();
        CUDA_CHECK(cudaStreamSynchronize(stream_));  // Wait for rollout completion
        auto t_rollout_end = std::chrono::high_resolution_clock::now();
        float rollout_ms = std::chrono::duration<float, std::milli>(t_rollout_end - t_rollout_start).count();
        total_rollout_ms += rollout_ms;
        
        // Compute weights (on stream, with annealed lambda)
        auto t_weight_start = std::chrono::high_resolution_clock::now();
        computeWeights(lambda_annealed);  // Pass annealed lambda
        CUDA_CHECK(cudaStreamSynchronize(stream_));  // Wait for weight computation
        auto t_weight_end = std::chrono::high_resolution_clock::now();
        float weight_ms = std::chrono::duration<float, std::milli>(t_weight_end - t_weight_start).count();
        total_weight_ms += weight_ms;
        
        // üî• Update nominal control (MPPIÊ†∏ÂøÉÁÆóÊ≥ï, on stream)
        auto t_update_start = std::chrono::high_resolution_clock::now();
        updateNominalControl();
        CUDA_CHECK(cudaStreamSynchronize(stream_));  // Wait for control update
        auto t_update_end = std::chrono::high_resolution_clock::now();
        float update_ms = std::chrono::duration<float, std::milli>(t_update_end - t_update_start).count();
        total_update_ms += update_ms;
        
        if (params_.use_iterative_mppi && num_iters > 1) {
            ROS_INFO("[MPPI-GPU] Iter %d/%d: lambda=%.2f, rollout=%.2fms, weight=%.2fms, update=%.2fms",
                     iter + 1, num_iters, lambda_annealed, rollout_ms, weight_ms, update_ms);
        }
    }
    
    last_timing_.rollout_time_ms = total_rollout_ms;
    last_timing_.weight_time_ms = total_weight_ms;
    float update_time_ms = total_update_ms;
    
    // üöÄ Copy results back (Async)
    CUDA_CHECK(cudaMemcpyAsync(h_trajectory_costs_.data(), d_trajectory_costs_,
                         params_.num_samples * sizeof(float), cudaMemcpyDeviceToHost, stream_));
    CUDA_CHECK(cudaMemcpyAsync(h_weights_.data(), d_weights_,
                         params_.num_samples * sizeof(float), cudaMemcpyDeviceToHost, stream_));
    
    // Wait for all async operations to complete
    CUDA_CHECK(cudaStreamSynchronize(stream_));
    
    // Extract optimal trajectory (CPU)
    extractOptimalTrajectory(start_pos, start_vel, optimal_path);
    
    auto t_end = std::chrono::high_resolution_clock::now();
    last_timing_.total_time_ms = 
        std::chrono::duration<float, std::milli>(t_end - t_start).count();
    
    ROS_INFO("[MPPI-GPU] ‚è±Ô∏è Timing: Total=%.2fms (Rollout=%.2fms, Weight=%.2fms, Update=%.2fms)",
             last_timing_.total_time_ms, last_timing_.rollout_time_ms, 
             last_timing_.weight_time_ms, update_time_ms);
    
    return true;
}

void MPPIGPUPlanner::launchRolloutKernel() {
    // Setup dynamics
    SimpleDynamicsGPU dynamics;
    dynamics.max_velocity = params_.max_velocity;
    dynamics.max_acceleration = params_.max_acceleration;
    dynamics.dt = params_.dt;
    
    // Setup cost function (üöÄ Using texture object + üî• dynamic obstacles)
    CostFunctionGPU cost_func;
    cost_func.w_obstacle = params_.w_obstacle;
    cost_func.w_smoothness = params_.w_smoothness;
    cost_func.w_goal = params_.w_goal;
    cost_func.w_velocity = params_.w_velocity;
    cost_func.safe_distance = params_.safe_distance;
    cost_func.edt_texture = edt_texture_;  // üöÄ Pass texture object to kernel
    cost_func.grid_size_x = grid_size_x_;
    cost_func.grid_size_y = grid_size_y_;
    cost_func.grid_size_z = grid_size_z_;
    cost_func.resolution = grid_resolution_;
    cost_func.origin_x = grid_origin_x_;
    cost_func.origin_y = grid_origin_y_;
    cost_func.origin_z = grid_origin_z_;
    
    // üî• Dynamic obstacles
    cost_func.w_dynamic = 1.0f;  // TODO: Make this configurable
    cost_func.dynamic_positions = d_dynamic_positions_;
    cost_func.dynamic_radii = d_dynamic_radii_;
    cost_func.num_dynamic_obstacles = num_dynamic_obstacles_;
    cost_func.dynamic_horizon = dynamic_horizon_;
    cost_func.dynamic_dt = dynamic_dt_;
    
    // Kernel launch configuration
    int num_blocks = (params_.num_samples + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;
    
    // Random seed
    unsigned long long seed = std::chrono::system_clock::now().time_since_epoch().count();
    
    // üöÄ Launch kernel on stream (üî• Ê∑ªÂä†control_samplesÂèÇÊï∞)
    mppiRolloutKernel<<<num_blocks, THREADS_PER_BLOCK, 0, stream_>>>(
        d_initial_state_,
        d_goal_pos_,
        d_goal_vel_,
        d_nominal_control_,
        dynamics,
        cost_func,
        params_.sigma_acc,
        params_.horizon_steps,
        params_.num_samples,
        d_trajectory_costs_,
        d_control_samples_,  // üî• Â≠òÂÇ®ÈááÊ†∑ÊéßÂà∂
        seed
    );
    
    CUDA_CHECK(cudaGetLastError());
}

void MPPIGPUPlanner::computeWeights(float lambda) {
    int num_blocks = (params_.num_samples + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;
    
    // Reset min_cost and weight_sum (async)
    float init_min = 1e10f;
    float init_sum = 0.0f;
    CUDA_CHECK(cudaMemcpyAsync(d_min_cost_, &init_min, sizeof(float), 
                              cudaMemcpyHostToDevice, stream_));
    CUDA_CHECK(cudaMemcpyAsync(d_weight_sum_, &init_sum, sizeof(float), 
                              cudaMemcpyHostToDevice, stream_));
    
    // üöÄ Compute weights (on stream, with provided lambda)
    computeWeightsKernel<<<num_blocks, THREADS_PER_BLOCK, 0, stream_>>>(
        d_trajectory_costs_,
        d_weights_,
        d_min_cost_,
        lambda,  // Use provided lambda (may be annealed)
        params_.num_samples
    );
    CUDA_CHECK(cudaGetLastError());
    
    // üöÄ Normalize weights (on stream)
    normalizeWeightsKernel<<<num_blocks, THREADS_PER_BLOCK, 0, stream_>>>(
        d_weights_,
        d_weight_sum_,
        params_.num_samples
    );
    CUDA_CHECK(cudaGetLastError());
}

void MPPIGPUPlanner::updateNominalControl() {
    // Grid: num_timesteps, Block: THREADS_PER_BLOCK
    int num_blocks = params_.horizon_steps;
    
    // ÔøΩ Âä†ÊùÉÊéßÂà∂Êõ¥Êñ∞: u_new = u_nominal + Œ£(w[i] * du[i]) (on stream)
    weightedControlUpdateKernel<<<num_blocks, THREADS_PER_BLOCK, 0, stream_>>>(
        d_weights_,
        d_control_samples_,
        d_nominal_control_,
        d_updated_control_,
        params_.horizon_steps,
        params_.num_samples
    );
    CUDA_CHECK(cudaGetLastError());
    
    // üî• Copy updated control back to nominal (for next iteration, device-to-device)
    CUDA_CHECK(cudaMemcpyAsync(d_nominal_control_, d_updated_control_,
                         params_.horizon_steps * CONTROL_DIM * sizeof(float),
                         cudaMemcpyDeviceToDevice, stream_));
    
    // Also update host-side nominal control (async)
    CUDA_CHECK(cudaMemcpyAsync(h_nominal_control_.data(), d_updated_control_,
                         params_.horizon_steps * CONTROL_DIM * sizeof(float),
                         cudaMemcpyDeviceToHost, stream_));
}

void MPPIGPUPlanner::extractOptimalTrajectory(const Vector3d& start_pos,
                                              const Vector3d& start_vel,
                                              std::vector<Vector3d>& path) {
    // Find best trajectory (minimum cost)
    int best_idx = 0;
    float min_cost = h_trajectory_costs_[0];
    for (int i = 1; i < params_.num_samples; i++) {
        if (h_trajectory_costs_[i] < min_cost) {
            min_cost = h_trajectory_costs_[i];
            best_idx = i;
        }
    }
    
    ROS_INFO("[MPPI-GPU] Best trajectory: idx=%d, cost=%.2f, weight=%.4f",
             best_idx, min_cost, h_weights_[best_idx]);
    
    // ÁÆÄÂåñÁâà: Áõ¥Êé•ËøîÂõûstartÂà∞goalÁöÑÁõ¥Á∫øË∑ØÂæÑ
    // TODO: ÈúÄË¶Å‰øùÂ≠òÂπ∂ËøîÂõûÂÆûÈôÖÁöÑÊúÄ‰ºòËΩ®Ëøπ
    path.clear();
    path.push_back(start_pos);
    
    // Ê∑ªÂä†‰∏≠Èó¥ÁÇπ(ÁÆÄÂåñ)
    for (int i = 1; i < 5; i++) {
        float alpha = i / 5.0f;
        Vector3d waypoint = start_pos + alpha * (Vector3d(h_goal_pos_[0], h_goal_pos_[1], h_goal_pos_[2]) - start_pos);
        path.push_back(waypoint);
    }
    
    path.push_back(Vector3d(h_goal_pos_[0], h_goal_pos_[1], h_goal_pos_[2]));
}

} // namespace ego_planner
